# ML Pipeline Requirements for TRL SFT Training with PyTorch (A100 GPU)
torch>=2.0.0
transformers>=4.38.0,<4.50  # Compatible with autogluon
datasets>=2.7.0
trl>=0.7.0
accelerate>=0.20.0
numpy>=1.21.0
peft>=0.4.0  # For LoRA fine-tuning

# Hugging Face authentication
huggingface-hub>=0.17.0

# GPU optimizations
bitsandbytes>=0.41.0  # For quantization if needed

# Lion optimizer
lion-pytorch>=0.1.2

# Extreme quantization for embedded deployment
# auto-gptq>=0.5.0  # Temporarily disabled due to build issues - use optimum instead
optimum[auto-gptq]>=1.12.0  # For GPTQ quantization via optimum

# SageMaker training (optional, for cloud deployment)
sagemaker>=2.100.0

# Compatibility fixes for SageMaker environment
pyarrow>=4.0.0,<20.0.0  # Compatible with mlflow and autogluon
onnxruntime>=1.15.0,<2.0.0  # Required by amazon-sagemaker-jupyter-ai-q-developer
nvidia-ml-py3>=7.352.0,<8.0.0  # Required by autogluon-multimodal