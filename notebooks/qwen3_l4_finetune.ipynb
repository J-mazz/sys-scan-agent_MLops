{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2b7c23",
   "metadata": {},
   "source": [
    "# Qwen3-4B Fine-Tuning on NVIDIA L4 (QLoRA via Unsloth Nightly)\n",
    "This notebook adapts **Qwen3-4B** with the `jmazz/sys-scan-linux-synthetic` corpus, following the repository's reliability-first MLOps guidance. Assume execution on a managed NVIDIA L4 (or similar bf16-capable GPU) with nightly Unsloth kernels installed.\n",
    "\n",
    "**Safety & reproducibility guardrails**:\n",
    "- Export credentials such as `HF_TOKEN` and `WANDB_API_KEY` _before_ running Section 1; never hard-code secrets in the notebook.\n",
    "- Outputs remain synthetic and defensive—do not repurpose the pipeline for offensive tooling or real telemetry.\n",
    "- Maintain a known-good adapter or base checkpoint to guarantee rollback paths if experiments diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ef8a6",
   "metadata": {},
   "source": [
    "## 1. Set Up Environment\n",
    "Provision the nightly Unsloth toolchain, validate the GPU, and register deterministic defaults before continuing.\n",
    "\n",
    "**Checklist**\n",
    "1. Remove any previously installed Unsloth wheels (prevents API drift).\n",
    "2. Install nightly `unsloth` and `unsloth_zoo` from source in editable mode.\n",
    "3. Confirm the L4 exposes bf16 compute and at least 24 GiB VRAM.\n",
    "4. Define shared constants (paths, seeds, dataset identifiers).\n",
    "5. Restart the kernel after installation so CUDA kernels are refreshed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Install nightly Unsloth, verify GPU capability, and set reproducible defaults.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def _run_pip(args: Iterable[str], allow_failure: bool = False) -> None:\n",
    "    \"\"\"Execute pip safely, optionally tolerating failures (e.g., uninstall when missing).\"\"\"\n",
    "    completed = subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=False, text=True)\n",
    "    if completed.returncode != 0 and not allow_failure:\n",
    "        raise RuntimeError(\n",
    "            f\"pip {' '.join(args)} failed with code {completed.returncode}: {completed.stderr}\"\n",
    "        )\n",
    "\n",
    "# Remove legacy wheels that might conflict with new nightly APIs.\n",
    "for pkg in (\"unsloth\", \"unsloth_zoo\"):\n",
    "    _run_pip([\"uninstall\", pkg, \"-y\"], allow_failure=True)\n",
    "\n",
    "# Install Unsloth nightly (editable mode ensures consistent rebuilds if repo already cloned).\n",
    "_run_pip([\n",
    "    \"install\",\n",
    "    \"--no-deps\",\n",
    "    \"--force-reinstall\",\n",
    "    \"git+https://github.com/unslothai/unsloth.git@main#egg=unsloth\",\n",
    "])\n",
    "_run_pip([\n",
    "    \"install\",\n",
    "    \"--no-deps\",\n",
    "    \"--force-reinstall\",\n",
    "    \"git+https://github.com/unslothai/unsloth.git@main#subdirectory=unsloth_zoo&egg=unsloth_zoo\",\n",
    "])\n",
    "\n",
    "def assert_l4_ready() -> None:\n",
    "    if not torch.cuda.is_available():\n",
    "        raise EnvironmentError(\"CUDA device not detected. Ensure the L4 is attached before continuing.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    name = torch.cuda.get_device_name(device)\n",
    "    props = torch.cuda.get_device_properties(device)\n",
    "    if \"L4\" not in name:\n",
    "        raise EnvironmentError(f\"Expected NVIDIA L4 GPU; detected {name} instead.\")\n",
    "    if not torch.cuda.is_bf16_supported():\n",
    "        raise EnvironmentError(\"bf16 is required for this workflow. Update drivers/CUDA for L4 bf16 support.\")\n",
    "    total_gib = props.total_memory / 1024**3\n",
    "    if total_gib < 24:\n",
    "        raise EnvironmentError(\n",
    "            f\"Insufficient GPU memory: {total_gib:.1f} GiB detected; L4 instances expose ≥24 GiB.\")\n",
    "    print(\n",
    "        f\"GPU check passed — {name} with {total_gib:.1f} GiB, compute capability {props.major}.{props.minor}.\"\n",
    ",\n",
    ")\n",
    "\n",
    "assert_l4_ready()\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ProjectPaths:\n",
    "    project_root: Path = Path.cwd()\n",
    "    dataset_id: str = \"jmazz/sys-scan-linux-synthetic\"\n",
    "    dataset_revision: str = \"main\"\n",
    "    log_dir: Path = project_root / \"logs\" / \"qwen3_l4\"\n",
    "    output_dir: Path = project_root / \"outputs\" / \"qwen3_l4\"\n",
    "    cache_dir: Path = project_root / \"cache\" / \"hf-datasets\"\n",
    "    seed: int = 42\n",
    "    run_stamp: str = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    def run_dir(self) -> Path:\n",
    "        return self.output_dir / self.run_stamp\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "for directory in (paths.log_dir, paths.output_dir, paths.cache_dir, paths.run_dir()):\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "seed_everything(paths.seed)\n",
    "print(f\"Deterministic seed set to {paths.seed}\")\n",
    "print(f\"Artifacts will be saved to {paths.run_dir()}\")\n",
    "\n",
    "print(\"Restart the kernel now if any packages were (re)installed before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444bcee",
   "metadata": {},
   "source": [
    "## 2. Load Dataset & Validate Schema\n",
    "Use the curated sys-scan synthetic corpus from Hugging Face, enforce the ground-truth schema, and split deterministic shards for train/validation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
